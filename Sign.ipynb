{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd '/content/gdrive/MyDrive/microsoft_ia/sign'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = None\n",
    "accumulated_weight = 0.5\n",
    "\n",
    "#Création des dimensions du ROI\n",
    "\n",
    "ROI_top = 50\n",
    "ROI_bottom = 250\n",
    "ROI_right = 50\n",
    "ROI_left = 250\n",
    "\n",
    "#Project: gesture-recognition, License: MIT License, OpenSource\n",
    "\n",
    "def cal_accum_avg(frame, accumulated_weight):\n",
    "    global background\n",
    "    \n",
    "    if background is None:\n",
    "        background = frame.copy().astype(\"float\")\n",
    "        return None\n",
    "    \n",
    "    cv2.accumulateWeighted(frame, background, accumulated_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_hand(frame, threshold=25):\n",
    "    global background\n",
    "    \n",
    "    diff = cv2.absdiff(background.astype(\"uint8\"), frame)\n",
    "    _ , thresholded = cv2.threshold(diff, threshold,255,cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Saisi les contours\n",
    "    contours, hierarchy = cv2.findContours(thresholded.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if len(contours) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        hand_segment_max_cont = max(contours, key=cv2.contourArea)\n",
    "        return (thresholded, hand_segment_max_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "num_frames = 0\n",
    "element = 'A'\n",
    "\n",
    "num_imgs_taken = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    \n",
    "    # Eviter l'inversement de l'image\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_copy = frame.copy()\n",
    "    roi = frame[ROI_top:ROI_bottom, ROI_right:ROI_left]\n",
    "    gray_frame = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    gray_frame = cv2.GaussianBlur(gray_frame, (9, 9), 0)\n",
    "    \n",
    "    if num_frames < 60:\n",
    "        cal_accum_avg(gray_frame, accumulated_weight)\n",
    "        \n",
    "        # Détection du Background\n",
    "        if num_frames <= 299:\n",
    "            cv2.putText(frame_copy, \"Chargement..\", (80, 400), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,0,255), 2)\n",
    "            \n",
    "    # Configuration\n",
    "    elif num_frames <= 300: \n",
    "        hand = segment_hand(gray_frame)\n",
    "        cv2.putText(frame_copy, \"Configuration..\" + str(element), (200, 400), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255),2)\n",
    "        \n",
    "        # Voir si la main est bien détectée\n",
    "        if hand is not None:\n",
    "            \n",
    "            thresholded, hand_segment = hand\n",
    "            \n",
    "            # Dessiner les contours de la main\n",
    "            cv2.drawContours(frame_copy, [hand_segment + (ROI_right,ROI_top)], -1, (255, 0, 0),1)\n",
    "            \n",
    "            cv2.putText(frame_copy, str(num_frames)+\" Pour \"+ str(element),(70, 45), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "            \n",
    "            # Affiche l'image prise\n",
    "            cv2.imshow(\"Image traitée\", thresholded)\n",
    "    \n",
    "    else: \n",
    "        # Segmentation de la main\n",
    "        hand = segment_hand(gray_frame)\n",
    "        \n",
    "        # Repérer si la main est là\n",
    "        if hand is not None:\n",
    "            \n",
    "            # unpack the thresholded img and the max_contour...\n",
    "            thresholded, hand_segment = hand\n",
    "            \n",
    "            # Dessiner le contour de la main\n",
    "            cv2.drawContours(frame_copy, [hand_segment + (ROI_right, ROI_top)], -1, (255, 0, 0),1) \n",
    "            cv2.putText(frame_copy, str(num_frames), (70, 45), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.putText(frame_copy, str(num_imgs_taken) + 'Enregistrement pour ' + str(element), (200, 400), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "            \n",
    "            # Afficher l'image de la main traitée\n",
    "            cv2.imshow(\"Image traitée\", thresholded)\n",
    "            if num_imgs_taken <= 299:\n",
    "                cv2.imwrite(r\"C:\\\\Users\\\\utilisateur\\\\Documents\\\\data_sign\\\\\"+str(element)+\"\\\\\"+str(num_imgs_taken+1) +'.jpg', thresholded)\n",
    "                \n",
    "            else:\n",
    "                break\n",
    "            num_imgs_taken +=1\n",
    "            \n",
    "        else:\n",
    "            cv2.putText(frame_copy, 'Pas de main détectée !', (200, 400), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "            \n",
    "    # Drawing ROI on frame copy\n",
    "    cv2.rectangle(frame_copy, (ROI_left, ROI_top), (ROI_right,ROI_bottom), (255,128,0), 3)\n",
    "    \n",
    "    # increment the number of frames for tracking\n",
    "    num_frames += 1\n",
    "    # Display the frame with segmented hand\n",
    "    cv2.imshow(\"Sign Detection\", frame_copy)\n",
    "    # Closing windows with Esc key...(any other key with ord can be used too.)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "        \n",
    "#Releasing the camera & destroying all the windows...\n",
    "cv2.destroyAllWindows()\n",
    "cam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_direction = \"./data_sign\"\n",
    "categories = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z','_SPACE']\n",
    "\n",
    "for category in categories:\n",
    "    path = os.path.join(data_direction, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path, img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 200, 3)\n"
     ]
    }
   ],
   "source": [
    "print(img_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "IMG_SIZE = 64\n",
    "\n",
    "new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "new_array = cv2.cvtColor(new_array, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(new_array, cmap ='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "\n",
    "def create_data_list():\n",
    "    for category in categories:\n",
    "        path = os.path.join(data_direction, category)\n",
    "        class_num = categories.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            img_array = cv2.imread(os.path.join(path, img))\n",
    "            new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "            data_list.append([new_array, class_num])\n",
    "       \n",
    "    \n",
    "create_data_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8100"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for feature, label in data_list:\n",
    "    images.append(feature)\n",
    "    labels.append(label)\n",
    "    \n",
    "images = np.array(images).reshape(-1, IMG_SIZE, IMG_SIZE, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_app, x_val, y_app, y_val = train_test_split(images, labels, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_app = x_app.astype('float')/255\n",
    "x_val = x_val.astype('float')/255\n",
    "\n",
    "y_app = np.array(y_app)\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_app.shape :\t  (6480, 64, 64, 3)\n",
      "x_val.shape :\t  (1620, 64, 64, 3)\n",
      "y_app.shape :\t  (6480,)\n",
      "y_val.shape :\t  (1620,)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_app.shape :\\t \", x_app.shape)\n",
    "print(\"x_val.shape :\\t \", x_val.shape)\n",
    "print(\"y_app.shape :\\t \", y_app.shape)\n",
    "print(\"y_val.shape :\\t \", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_app.shape :\t  (6480, 27)\n",
      "y_val.shape :\t  (1620, 27)\n"
     ]
    }
   ],
   "source": [
    "y_app = tf.keras.utils.to_categorical(y_app, 27)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, 27)\n",
    "\n",
    "print(\"y_app.shape :\\t \",y_app.shape)\n",
    "print(\"y_val.shape :\\t \",y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(27, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer ='adam',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "augmentation = ImageDataGenerator(samplewise_center=True, \n",
    "                                  samplewise_std_normalization=True, \n",
    "                                  validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(r\"model_sign\")\n",
    "background = None\n",
    "accumulated_weight = 0.5\n",
    "ROI_top = 50\n",
    "ROI_bottom = 250\n",
    "ROI_right = 50\n",
    "ROI_left = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = {0:'A',1:'B',2:'C',3:'D',4:'E',5:'F',6:'G',7:'H',8:'I',9:'J',10:'K',11:'L',12:'M',13:'N',14:'O',15:'P',16:'Q',17:'R',18:'S',19:'T',20:'U',21:'V',22:'W',23:'X',24:'Y',25:'Z',26:'_SPACE'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_accum_avg(frame, accumulated_weight):\n",
    "    global background\n",
    "    \n",
    "    if background is None:\n",
    "        background = frame.copy().astype(\"float\")\n",
    "        return None\n",
    "    cv2.accumulateWeighted(frame, background, accumulated_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_hand(frame, threshold=25):\n",
    "    global background\n",
    "    \n",
    "    diff = cv2.absdiff(background.astype(\"uint8\"), frame)\n",
    "    _ , thresholded = cv2.threshold(diff, threshold, 255,cv2.THRESH_BINARY)\n",
    "    \n",
    "     #Fetching contours in the frame (These contours can be of hand or any other object in foreground) …\n",
    "    contours, hierarchy = cv2.findContours(thresholded.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # If length of contours list = 0, means we didn't get any contours...\n",
    "    \n",
    "    if len(contours) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        # The largest external contour should be the hand \n",
    "        hand_segment_max_cont = max(contours, key=cv2.contourArea)\n",
    "        \n",
    "        # Returning the hand segment(max contour) and the thresholded image of hand...\n",
    "        return (thresholded, hand_segment_max_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "num_frames =0\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    # flipping the frame to prevent inverted image of captured frame...\n",
    "    \n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_copy = frame.copy()\n",
    "    # ROI from the frame\n",
    "    roi = frame[ROI_top:ROI_bottom, ROI_right:ROI_left]\n",
    "    gray_frame = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    gray_frame = cv2.GaussianBlur(gray_frame, (9, 9), 0)\n",
    "    if num_frames < 70:\n",
    "        \n",
    "        cal_accum_avg(gray_frame, accumulated_weight)\n",
    "        \n",
    "        cv2.putText(frame_copy, \"Chargement\", (80, 400), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,0,255), 2)\n",
    "    \n",
    "    else: \n",
    "        # segmenting the hand region\n",
    "        hand = segment_hand(gray_frame)\n",
    "        \n",
    "        # Checking if we are able to detect the hand...\n",
    "        if hand is not None:\n",
    "            \n",
    "            thresholded, hand_segment = hand\n",
    "            # Drawing contours around hand segment\n",
    "            cv2.drawContours(frame_copy, [hand_segment + (ROI_right, ROI_top)], -1, (255, 0, 0),1)\n",
    "            \n",
    "            cv2.imshow(\"Image traitée\", thresholded)\n",
    "            \n",
    "            thresholded = cv2.resize(thresholded, (64, 64))\n",
    "            thresholded = cv2.cvtColor(thresholded, cv2.COLOR_GRAY2RGB)\n",
    "            thresholded = np.reshape(thresholded, (1,thresholded.shape[0],thresholded.shape[1],3))\n",
    "            \n",
    "            pred = model.predict(thresholded)\n",
    "            cv2.putText(frame_copy, word_dict[np.argmax(pred)], (170, 45), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "            \n",
    "    # Draw ROI on frame_copy\n",
    "    cv2.rectangle(frame_copy, (ROI_left, ROI_top), (ROI_right, ROI_bottom), (255,128,0), 3)\n",
    "    # incrementing the number of frames for tracking\n",
    "    num_frames += 1\n",
    "    # Display the frame with segmented hand\n",
    "    cv2.putText(frame_copy, \"Prédiction\", (10, 20), cv2.FONT_ITALIC, 0.5, (51,255,51), 1)\n",
    "    cv2.imshow(\"Sign Detection\", frame_copy)\n",
    "    # Close windows with Esc\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "# Release the camera and destroy all the windows\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
